# Инструкция по использованию скрипта парсинга

## Описание

Скрипт `parse_cottage_villages.py` предназначен для автоматического сбора информации о коттеджных поселках РФ из различных источников в интернете.

## Требования

### Установка зависимостей

```bash
pip install requests beautifulsoup4 lxml
```

Или используйте файл requirements.txt:

```bash
pip install -r requirements.txt
```

### Создание файла requirements.txt

Создайте файл `requirements.txt` со следующим содержимым:

```
requests>=2.31.0
beautifulsoup4>=4.12.0
lxml>=4.9.0
```

## Использование

### Базовое использование

```bash
python parse_cottage_villages.py
```

### Настройка параметров

Откройте файл `parse_cottage_villages.py` и измените параметры в функции `main()`:

```python
def main():
    parser = VillageParser()
    
    # Источники для парсинга
    sources = ['cian', 'domclick', 'yandex', 'cottage', 'poselki', 'avito']
    
    # Регионы для парсинга
    regions = ['moskovskaya-oblast', 'leningradskaya-oblast']
    
    # Количество страниц для парсинга
    max_pages = 5
    
    parser.run(sources=sources, regions=regions, max_pages=max_pages)
```

## Источники данных

Скрипт поддерживает парсинг из следующих источников:

1. **Cian.ru** - крупнейший портал недвижимости
2. **DomClick.ru** - портал Сбербанка
3. **Яндекс.Недвижимость** - агрегатор объявлений
4. **Cottage.ru** - специализированный портал
5. **Poselki.ru** - каталог коттеджных поселков
6. **Авито Недвижимость** - раздел коттеджных поселков

## Результаты

### Формат вывода

Результаты сохраняются в файл **"Результат парсинга информации в интернете.csv"** в формате CSV с кодировкой UTF-8-BOM (для корректного отображения в Excel).

### Структура данных

Файл содержит 43 поля согласно структуре таблицы из инструкции:

- **Блок 1:** Основная информация о поселке (7 полей)
- **Блок 2:** Характеристики поселка (8 полей)
- **Блок 3:** Контактная информация (8 полей)
- **Блок 4:** Квалификация по CHAMP (5 полей)
- **Блок 5:** Статус работы (7 полей)
- **Блок 6:** Результаты работы (4 поля)
- **Блок 7:** Дополнительная информация (4 поля)

### Логирование

Все действия скрипта логируются в файл `parsing.log` и выводятся в консоль.

## Особенности работы

### Задержки между запросами

Скрипт использует случайные задержки между запросами (2-5 секунд) для:
- Соблюдения правил использования сайтов
- Избежания блокировок
- Имитации человеческого поведения

### Обработка ошибок

Скрипт обрабатывает следующие ситуации:
- Ошибки сети (таймауты, недоступность сайтов)
- Изменение структуры страниц
- Отсутствие данных
- Дубликаты записей

### Удаление дубликатов

Скрипт автоматически удаляет дубликаты по названию поселка и адресу, объединяя данные из разных источников.

### Обогащение данных

Для первых 10 поселков скрипт дополнительно загружает детальные страницы для получения более полной информации.

## Ограничения

### Технические ограничения

1. **Антибот защита:** Некоторые сайты могут блокировать автоматические запросы
2. **Динамический контент:** Сайты с JavaScript могут требовать использования Selenium/Playwright
3. **Изменение структуры:** Структура страниц может изменяться, что требует обновления парсера

### Рекомендации

1. **Использовать прокси:** При большом объеме парсинга рекомендуется использовать прокси-серверы
2. **Увеличить задержки:** При блокировках увеличить задержки между запросами
3. **Использовать Selenium:** Для сайтов с динамическим контентом использовать Selenium или Playwright
4. **Ручная проверка:** Всегда проверять результаты парсинга вручную

## Расширение функциональности

### Добавление нового источника

1. Создайте метод `parse_new_source()` в классе `VillageParser`
2. Добавьте логику парсинга страниц
3. Добавьте источник в список `sources` в функции `main()`

### Улучшение парсинга

1. Добавьте специфичные селекторы для каждого источника
2. Улучшите извлечение данных (телефоны, email, адреса)
3. Добавьте валидацию данных

## Примеры использования

### Парсинг только Cian.ru для Московской области

```python
parser = VillageParser()
parser.run(sources=['cian'], regions=['moskovskaya-oblast'], max_pages=3)
```

### Парсинг всех источников для нескольких регионов

```python
parser = VillageParser()
parser.run(
    sources=['cian', 'domclick', 'yandex'],
    regions=['moskovskaya-oblast', 'leningradskaya-oblast'],
    max_pages=5
)
```

## Поддержка

При возникновении проблем:

1. Проверьте логи в файле `parsing.log`
2. Убедитесь, что все зависимости установлены
3. Проверьте доступность интернет-соединения
4. Обратитесь к разработчику скрипта

## Важные замечания

⚠️ **Внимание:** 
- Парсинг может нарушать правила использования некоторых сайтов
- Рекомендуется использовать официальные API, если они доступны
- При коммерческом использовании убедитесь в соблюдении законодательства
- Регулярно проверяйте актуальность данных

## Лицензия

Скрипт создан для внутреннего использования компании PASS24.online.
